{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Jurnal dengan K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import library\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Clustering\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans,SpectralClustering\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Decomposition\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "# Text\n",
    "import unicodedata, re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('detail_manajemen.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurnal = df[['judul', 'abstraksi']].dropna()\n",
    "jurnal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Mengubah teks menjadi lowercase\n",
    "    cleaned_text = text.lower()\n",
    "    # Menghapus angka\n",
    "    cleaned_text = re.sub(r\"\\d+\", \"\", cleaned_text)\n",
    "    # Menghapus white space\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    # Menghapus tanda baca\n",
    "    cleaned_text = cleaned_text.translate(str.maketrans(string.punctuation, \" \"*len(string.punctuation), \"\"))\n",
    "    # Hapus stopword\n",
    "    cleaned_text = stopword.remove(cleaned_text)\n",
    "    # Stemming\n",
    "    cleaned_text = stemmer.stem(cleaned_text)\n",
    "\n",
    "    cleaned_text = stemmer.stem(cleaned_text)\n",
    "\n",
    "    cleaned_text = cleaned_text.replace('\\n', ' ')\n",
    "    cleaned_text = cleaned_text.replace('\\r', ' ')\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize text\n",
    "jurnal['cleaned_abstraksi'] = jurnal['abstraksi'].apply(clean_text)\n",
    "jurnal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Apply the TF_idf vectorizer to get the sparse matrix of the TF_IDF process\"\"\"\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(jurnal['cleaned_abstraksi'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A simple view of the feature names\"\"\"\n",
    "print(vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimentional reduction PCA\n",
    "**Principal component analysis (PCA)** adalah teknik analisis statistik multivariat. Teknik analisis statistik yang paling populer sekarang dapat dikatakan adalah PCA. PCA digunakan dalam bidang pengenalan pola serta pemrosesan sinyal.\n",
    "\n",
    "PCA pada dasarnya merupakan dasar dari analisis data multivariat yang menerapkan metode proyeksi. Teknik analisis ini biasanya digunakan untuk meringkas tabel data multivariat dalam skala besar hingga bisa dijadikan kumpulan variabel yang lebih kecil atau indeks ringkasan. Dari situ, kemudian variabel dianalisis untuk mengetahui tren tertentu, klaster variabel, hingga outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(tfidf.toarray())\n",
    "cmv = pca.explained_variance_ratio_.cumsum()\n",
    "print(cmv)\n",
    "print(cmv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduksi Dimensi\n",
    "pca = PCA(n_components=40)\n",
    "pca_df = pca.fit_transform(tfidf)\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metode Elbow\n",
    "**Metode Elbow** adalah metode untuk menentukan jumlah cluster yang tepat melalui persentase hasil perbandingan antara jumlah cluster yang akan membentuk siku pada suatu titik. Jika nilai cluster pertama dengan nilai cluster kedua memberikan sudut dalam grafik atau nilainya mengalami penurunan paling besar maka jumlah nilai cluster tersebut yang tepat. Untuk mendapatkan perbandingannya adalah dengan menghitung Sum of Square Error (SSE) dari masing-masing nilai cluster. Karena semakin besar jumlah nilai cluster K, maka nilai SSE akan semakin kecil.\n",
    "\n",
    "$$\n",
    "S S E= \\sum_{K=1}^{K} \\sum_{X_{i}}\\left|x_{i}-c_{k}\\right|^{2}\n",
    "$$\n",
    "\n",
    "Keterangan:\\\n",
    "${K}$ = _cluster_ ke-c\\\n",
    "$x_{i}$ = jarak data obyek ke-i\\\n",
    "$c_{k}$ = pusat _cluster_ ke-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKm = KMeans(random_state=12)\n",
    "visualizer = KElbowVisualizer(modelKm, k=(1,12))\n",
    "\n",
    "visualizer.fit(tfidf)\n",
    "visualizer.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "K-Means Clustering merupakan algoritma yang efektif untuk menentukan cluster dalam sekumpulan data, di mana pada algortima tersebut dilakukan analisis kelompok yang mengacu pada pemartisian N objek ke dalam K kelompok (Cluster) berdasarkan nilai rata-rata (means) terdekat. Adapun persamaan yang sering digunakan dalam pemecahan masalah dalam menentukan jarak terdekat adalah persamaan Euclidean berikut :\n",
    "\n",
    "$$\n",
    "d(p, q)=\\sqrt{\\left(p_{1}-q_{1}\\right)^{2}+\\left(p_{2}-q_{2}\\right)^{2}+\\left(p_{3}-q_{3}\\right)^{2}}\n",
    "$$\n",
    "\n",
    "Keterangan:\\\n",
    "_d_ = jarak obyek\\\n",
    "_p_ = data\\\n",
    "_q_ = centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train the Kmeans with the best n of clusters\"\"\"\n",
    "modelKm = KMeans(n_clusters=3, random_state=12)\n",
    "modelKm.fit(tfidf)\n",
    "y_kmeans = modelKm.predict(tfidf)\n",
    "\n",
    "\"\"\"Dimensionality reduction used to plot in 2d representation\"\"\"\n",
    "pc=TruncatedSVD(n_components=2)\n",
    "X_new=pc.fit_transform(tfidf)\n",
    "centr=pc.transform(modelKm.cluster_centers_)\n",
    "\n",
    "print(centr)\n",
    "plt.scatter(X_new[:,0],X_new[:,1],c=y_kmeans, cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}